{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "919bd5fc-6019-4330-9435-5e94292c5819",
      "metadata": {},
      "source": [
        "---\n",
        "title: Classification Metrics Quiz\n",
        "keywords: [machine learning, machine learning classification, machine learning classification metrics, decision trees, python, precision, recall, f1 score, weighted, accuracy, linear regression]\n",
        "description: Test your knowledge in the machine learning classification metrics with an objective-type quiz\n",
        "author: Juma Shafara\n",
        "date: \"2024-06\"\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4ac70ad-f01f-4e31-bc72-52a538e083a4",
      "metadata": {},
      "source": [
        "![Photo by DATAIDEA](../../assets/banner4.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58be7be2-bb04-4b78-b8e8-4d9ca0181a4b",
      "metadata": {},
      "source": [
        "## 1. What does the accuracy metric measure in a classification model?\n",
        "   - A. The ratio of correctly predicted instances to the total instances.\n",
        "   - B. The proportion of positive cases that were correctly identified.\n",
        "   - C. The proportion of actual positives that were correctly identified.\n",
        "   - D. The proportion of predicted positive cases that were correct.\n",
        "\n",
        "<details class=\"mb-2\">\n",
        "<summary style=\"color: #3a6e68;\">\n",
        "    <b>Reveal answer</b>\n",
        "</summary>\n",
        "<p class=\"alert alert-success\">A. The ratio of correctly predicted instances to the total instances.</p>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd849140-ed16-4072-83ca-b7a9543886e6",
      "metadata": {},
      "source": [
        "## 2. Which metric is most suitable for evaluating the performance of a classification model when dealing with imbalanced datasets?\n",
        "   - A. Accuracy\n",
        "   - B. Precision\n",
        "   - C. Recall\n",
        "   - D. F1-Score\n",
        "     \n",
        "<details class=\"mb-2\">\n",
        "<summary style=\"color: #3a6e68;\">\n",
        "<b>Reveal answer</b>\n",
        "</summary>\n",
        "<p class=\"alert alert-success\">D. F1-Score</p>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bc80d76-78eb-4b80-84c6-4a9531dc3087",
      "metadata": {},
      "source": [
        "## 3.What does precision measure in the context of classification?\n",
        "   - A. The ratio of true positives to the sum of true positives and false positives.\n",
        "   - B. The ratio of true positives to the sum of true positives and false negatives.\n",
        "   - C. The ratio of correctly predicted instances to the total instances.\n",
        "   - D. The ratio of false negatives to the sum of false negatives and true positives.\n",
        "\n",
        "<details class=\"mb-2\">\n",
        "<summary style=\"color: #3a6e68;\">\n",
        "<b>Reveal answer</b>\n",
        "</summary>\n",
        "<p class=\"alert alert-success\">D. F1-Score\n",
        "</p>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dbd5b99-41aa-43d1-8fbf-4a2d5fed81fd",
      "metadata": {},
      "source": [
        "## 4. What does recall (or sensitivity) measure?\n",
        "   - A. The ratio of true positives to the sum of true positives and false positives.\n",
        "   - B. The ratio of true positives to the sum of true positives and false negatives.\n",
        "   - C. The ratio of true negatives to the sum of true negatives and false positives.\n",
        "   - D. The ratio of false negatives to the sum of false negatives and true positives.\n",
        "  \n",
        "<details class=\"mb-2\">\n",
        "<summary style=\"color: #3a6e68;\">\n",
        "<b>Reveal answer</b>\n",
        "</summary>\n",
        "<p class=\"alert alert-success\">B. The ratio of true positives to the sum of true positives and false positives.\n",
        "</p>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eeb0571d-2fc8-4bae-880c-4bc5522baf11",
      "metadata": {},
      "source": [
        "## 5. The F1-score is the harmonic mean of which two metrics?\n",
        "   - A. Accuracy and Precision\n",
        "   - B. Precision and Recall\n",
        "   - C. Recall and Specificity\n",
        "   - D. Specificity and Precision\n",
        "\n",
        "<details class=\"mb-2\">\n",
        "<summary style=\"color: #3a6e68;\">\n",
        "    <b>Reveal answer</b>\n",
        "</summary>\n",
        "<p class=\"alert alert-success\">B. Precision and Recall</p>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44b537b5-d84a-49f7-a047-6682e2fff01d",
      "metadata": {},
      "source": [
        "## 6. In a confusion matrix, what does the bottom-right cell represent?**\n",
        "   - A. True Positives (TP)\n",
        "   - B. True Negatives (TN)\n",
        "   - C. False Positives (FP)\n",
        "   - D. False Negatives (FN)\n",
        "\n",
        "<details class=\"mb-2\">\n",
        "<summary style=\"color: #3a6e68;\">\n",
        "    <b>Reveal answer</b>\n",
        "</summary>\n",
        "<p class=\"alert alert-success\">B. True Negatives (TN)</p>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bb237a2-dfd3-463a-a34e-163a99c8a0e1",
      "metadata": {},
      "source": [
        "## 7. Which metric would you use to measure the proportion of negative cases that were correctly identified?\n",
        "   - A. Sensitivity\n",
        "   - B. Specificity\n",
        "   - C. Precision\n",
        "   - D. Accuracy\n",
        "\n",
        "<details class=\"mb-2\">\n",
        "<summary style=\"color: #3a6e68;\">\n",
        "    <b>Reveal answer</b>\n",
        "</summary>\n",
        "<p class=\"alert alert-success\">B. Specificity</p>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e3d836f-d301-4ba8-9276-dd61072c6e44",
      "metadata": {},
      "source": [
        "## 8. What is the main drawback of using accuracy as the sole metric for evaluating a classification model?\n",
        "   - A. It does not consider the balance between positive and negative classes.\n",
        "   - B. It requires a balanced dataset.\n",
        "   - C. It only considers the correctly predicted positive cases.\n",
        "   - D. It only considers the correctly predicted negative cases.\n",
        "\n",
        "<details class=\"mb-2\">\n",
        "<summary style=\"color: #3a6e68;\">\n",
        "    <b>Reveal answer</b>\n",
        "</summary>\n",
        "<p class=\"alert alert-success\">A. It does not consider the balance between positive and negative classes.</p>\n",
        "</details>\n",
        "\n",
        "<h2 class=\"text-center\">End</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a87c046-4cc2-4d74-a05e-cd5c980c51fd",
      "metadata": {},
      "source": [
        "<h2>What's on your mind? Put it in the comments!</h2>\n",
        "<script src=\"https://utteranc.es/client.js\"\n",
        "        repo=\"dataideaorg/dataidea-science\"\n",
        "        issue-term=\"pathname\"\n",
        "        theme=\"github-dark\"\n",
        "        crossorigin=\"anonymous\"\n",
        "        async>\n",
        "</script>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
